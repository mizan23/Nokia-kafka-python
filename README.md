# NSP Kafka Alarm Consumer

A **productionâ€‘ready Kafka consumer and alarm correlation pipeline** for **Nokia NSP / NFMâ€‘T**.

This project consumes NSP fault notifications from Kafka, normalizes and correlates alarms inâ€‘memory, persists alarm lifecycle state in PostgreSQL, and exposes a clean CLI for operators.

Designed for **24Ã—7 carrierâ€‘grade operation** with:
- zero message loss
- idempotent DB writes
- safe shutdown & cleanup
- correlation without DB calls in the hot path

---

## âœ¨ Features

- ğŸ” Secure OAuth token lifecycle (auto refresh + revoke)
- ğŸ“¡ Kafka SSL consumer (manual offset commit)
- ğŸ§  Inâ€‘memory correlation cache (Power / LOSâ€‘OCH)
- ğŸ§¹ Intelligent alarm suppression (root/child logic)
- ğŸ—„ PostgreSQL active + history storage
- â™»ï¸ Retention cleanup
- ğŸ›  Operator CLI for alarms
- ğŸš€ systemdâ€‘ready service

---

## ğŸ§± Architecture Overview

```
NSP â†’ Kafka â†’ Consumer â†’ Normalize â†’ Correlate â†’ DB
                         â†“
                     Drop Noise
```

**Hot path is DBâ€‘free** â€” correlation uses only inâ€‘memory cache.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ full_flow_main.py          # Main entry point
â”œâ”€â”€ kafka_consumer.py          # Kafka SSL consumer
â”œâ”€â”€ alarm_normalizer.py        # Normalize NSP payloads
â”œâ”€â”€ alarm_filters.py           # Correlation + suppression rules
â”œâ”€â”€ alarm_cache.py             # Inâ€‘memory correlation cache
â”œâ”€â”€ alarm_lifecycle.py         # DB + cache lifecycle handler
â”œâ”€â”€ alarm_view.py              # CLI for active/history alarms
â”œâ”€â”€ object_parser.py           # Affected object parser
â”œâ”€â”€ severity_mapper.py         # NSP â†’ normalized severity
â”œâ”€â”€ token_manager.py           # OAuth token lifecycle
â”œâ”€â”€ create_kafka_subscription.py
â”œâ”€â”€ renew_subscription.py
â”œâ”€â”€ delete_subscription.py
â”œâ”€â”€ configuration.py           # Environment config
â”œâ”€â”€ cleanup_history.py         # Retention cleanup
â”œâ”€â”€ bootstrap_postgres_nsp.sh  # PostgreSQL bootstrap script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ›  Requirements

- Python **3.9+**
- PostgreSQL **13+**
- Kafka access from NSP
- OpenSSL libraries

Python packages:
```
confluent-kafka
psycopg2-binary
requests
python-dotenv
pytz
tabulate
```

---

## ğŸ”§ Installation

### 1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/your-org/nsp-kafka-alarm-consumer.git
cd nsp-kafka-alarm-consumer
```

### 2ï¸âƒ£ Create virtualenv

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ—„ PostgreSQL Setup

Run **once**:

```bash
chmod +x bootstrap_postgres_nsp.sh
./bootstrap_postgres_nsp.sh
```

Creates:
- `active_alarms`
- `alarm_history`
- JSONB indexes
- triggers

---

## ğŸ” Environment Configuration

Create `.env` file:

```env
NSP_SERVER=192.168.42.7
NSP_USERNAME=client_id
NSP_PASSWORD=client_secret
KAFKA_KEYSTORE_PASSWORD=change_me
```

---

## â–¶ï¸ Running Manually

```bash
source venv/bin/activate
python full_flow_main.py
```

What happens:
1. OAuth token acquired
2. Kafka subscription created
3. Cache preloaded from DB
4. Kafka consumer starts
5. Alarms normalized â†’ correlated â†’ stored

---

## âš™ï¸ Running as systemd Service (Recommended)

### Create log directory

```bash
sudo mkdir -p /var/log/nsp
sudo chown $USER:$USER /var/log/nsp
```

### Create service file

```bash
sudo nano /etc/systemd/system/nsp-kafka-consumer.service
```

Paste:

```ini
[Unit]
Description=NSP Kafka Alarm Consumer
After=network.target postgresql.service
Wants=postgresql.service

[Service]
Type=simple
User=mizan
Group=mizan
WorkingDirectory=/home/mizan/kafka-python
ExecStart=/home/mizan/kafka-python/venv/bin/python full_flow_main.py
Environment=PYTHONUNBUFFERED=1
Restart=always
RestartSec=10
StandardOutput=append:/var/log/nsp/nsp-consumer.log
StandardError=append:/var/log/nsp/nsp-consumer.err
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

### Enable & start

```bash
sudo systemctl daemon-reload
sudo systemctl enable nsp-kafka-consumer
sudo systemctl start nsp-kafka-consumer
```

### Logs

```bash
tail -f /var/log/nsp/nsp-consumer.log
tail -f /var/log/nsp/nsp-consumer.err
```

---

## ğŸ§  Alarm Correlation Logic

### Power Correlation

- **Root**: `Power Issue` (PHYSICALCONNECTION)
- **Children**:
  - Power Adjustment Required
  - Power Adjustment Failure
- **Window**: Â±10 minutes
- **Match**: OPS shelf span

### LOSâ€‘OCH Correlation

- **Root**: Loss of signal â€“ OCH (CRITICAL)
- **Children**:
  - Transport Failure
  - OPS Protection Loss of Redundancy
- **Window**: Â±30 seconds
- **Match priority**:
  1. OPS span
  2. Same NE

Children are **suppressed**, roots always pass.

---

## ğŸ§ª Alarm Viewer CLI

### Active alarms

```bash
python alarm_view.py active --limit 30
```

### Correlated only

```bash
python alarm_view.py active --correlated-only
```

### History

```bash
python alarm_view.py history --severity CRITICAL
```

### Full alarm JSON

```bash
python alarm_view.py active-full <alarm_id>
```

---

## ğŸ§¹ Retention Cleanup

```bash
python cleanup_history.py
```

Deletes alarms older than **90 days**.

---

## ğŸ›‘ Safe Shutdown Guarantees

On SIGTERM / SIGINT:

- Kafka consumer stops
- Subscription deleted
- Token revoked
- Offsets committed only after DB success

No duplicates. No leaks.

---

## ğŸš€ Production Notes

- Consumer group is **stable**
- Manual commits guarantee **exactâ€‘once DB writes**
- Correlation cache prevents DB amplification
- JSONB indexes keep queries fast

---

## ğŸ“œ License

MIT License

---

## ğŸ¤ Contributing

PRs welcome. Keep hotâ€‘path logic **DBâ€‘free**.

---

## ğŸ§  Author

Built for realâ€‘world NSP deployments â€” not demos.

